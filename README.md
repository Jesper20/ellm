# ellm

GPU Server via Docker
    - codellama: Code-Feedback_300_1 to Code-Feedback_300_21 [completed]
    - llama3:70b: alpaca_prompts_only

Desktop
    - mistral: sharegpt-english_100_1 to sharegpt-english_100_30 [in progress]
